{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import sklearn.model_selection as model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all file names in list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [filename.split('.')[0] for filename in os.listdir('food') if filename.endswith('jpg')]\n",
    "names.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ResNet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "layer = model._modules.get('avgpool')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Extracting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are transformed into a form expected by ResNet50 and then we obtain the internal representation (corresponding to the second-to-last layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "FEATURE_SIZE = 2048\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file: str) -> torch.Tensor:\n",
    "  input_image = Image.open(file)\n",
    "  input_tensor = transform(input_image)\n",
    "  input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "  features = torch.zeros(FEATURE_SIZE)\n",
    "  def store_features(m, i, o):\n",
    "    features.copy_(o.data.reshape(-1))\n",
    "  h = layer.register_forward_hook(store_features)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    model(input_batch)\n",
    "\n",
    "  h.remove()\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [extract_features(f'food/{name}.jpg') for name in tqdm(names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_t = torch.stack(features)\n",
    "torch.save(features_t, 'data/features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_t = torch.load('data/features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach (this wasn't good enough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naÃ¯ve approach (not using the training data) is to compare image representations using cosine similarity. This yields an accuracy of ~64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "\n",
    "def predict_cos_(a: str, b: str, c: str) -> int:\n",
    "  a_features = features_t[names.index(a)].reshape(-1)\n",
    "  b_features = features_t[names.index(b)].reshape(-1)\n",
    "  c_features = features_t[names.index(c)].reshape(-1)\n",
    "  return int(cos(a_features, c_features) <= cos(a_features, b_features))\n",
    "\n",
    "def predict_cos(lines: List[str]) -> torch.Tensor:\n",
    "  y_pred = []\n",
    "  for line in lines:\n",
    "    [a, b, c] = line.split(' ')\n",
    "    y_pred.append(predict_cos_(a, b, c))\n",
    "  return torch.tensor(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "unsure = 0\n",
    "total = 0\n",
    "\n",
    "with open('train_triplets.txt') as f:\n",
    "  for l in tqdm(f.read().splitlines()):\n",
    "    [a, b, c] = l.split(' ')\n",
    "    prediction = predict_cos_(a, b, c)\n",
    "    if prediction == 1:\n",
    "      correct += 1\n",
    "    elif prediction == 0:\n",
    "      wrong += 1\n",
    "    else:\n",
    "      correct += 0.5\n",
    "      wrong += 0.5\n",
    "      unsure += 1\n",
    "    total += 1\n",
    "\n",
    "correct / total, wrong / total, unsure / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a fully connected NN on the binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 3 * FEATURE_SIZE\n",
    "\n",
    "class FCN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.do = nn.Dropout(p=0.8)\n",
    "    self.fc1 = nn.Linear(INPUT_SIZE, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 256)\n",
    "    self.fc3 = nn.Linear(256, 64)\n",
    "    self.fc4 = nn.Linear(64, 16)\n",
    "    self.fc5 = nn.Linear(16, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu(self.do(x))\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = torch.relu(self.fc3(x))\n",
    "    x = torch.relu(self.fc4(x))\n",
    "    x = torch.sigmoid(self.fc5(x))\n",
    "    return x\n",
    "\n",
    "net = FCN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(a: str, b: str, c: str) -> torch.Tensor:\n",
    "  a_features = features_t[names.index(a)].reshape(-1)\n",
    "  b_features = features_t[names.index(b)].reshape(-1)\n",
    "  c_features = features_t[names.index(c)].reshape(-1)\n",
    "  return torch.cat([a_features, b_features, c_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "with open('train_triplets.txt') as f:\n",
    "  for l in tqdm(f.read().splitlines()):\n",
    "    [a, b, c] = l.split(' ')\n",
    "\n",
    "    label = round(random.random())\n",
    "    if label:\n",
    "      X.append(prepare_features(a, b, c))\n",
    "    else:\n",
    "      X.append(prepare_features(a, c, b))\n",
    "    y.append(label)\n",
    "\n",
    "X_t = torch.stack(X)\n",
    "y_t = torch.tensor(y)\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_t, 'data/X.pt')\n",
    "torch.save(y_t, 'data/y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = torch.load('data/X.pt')\n",
    "y_t = torch.load('data/y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_t.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_t, y_t, test_size=0.2, random_state=42)\n",
    "\n",
    "del X_t\n",
    "del y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "test_set = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "net.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  running_loss = 0.0\n",
    "  for i, data in enumerate(train_loader):\n",
    "    X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X).squeeze()\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "  print(f'[{epoch + 1}] average loss per epoch: {running_loss / len(train_loader):.3f}')\n",
    "\n",
    "torch.save(net.state_dict(), 'data/net.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FCN()\n",
    "net.load_state_dict(torch.load('data/net.pt'))\n",
    "net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    X, y = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    output = net(X).squeeze()\n",
    "    y_pred = torch.round(output)\n",
    "    \n",
    "    total += y.size(0)\n",
    "    correct += (y_pred == y).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} test queries: {100 * correct // total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fcn(lines: List[str]) -> torch.Tensor:\n",
    "  X = []\n",
    "  for line in lines:\n",
    "    [a, b, c] = line.split(' ')\n",
    "    X.append(prepare_features(a, b, c))\n",
    "  X_t = torch.stack(X).to(device)\n",
    "  del X\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    output = net(X_t).squeeze()\n",
    "  y_pred = torch.round(output)\n",
    "\n",
    "  return y_pred.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict_fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_triplets.txt') as f:\n",
    "  y_pred = predict(f.read().splitlines())\n",
    "  np.savetxt('submission.txt', y_pred.numpy(), fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_example(inp: str):\n",
    "  plt.figure(figsize=(25, 25))\n",
    "  names = inp.split(' ')\n",
    "  for index, name in enumerate(names):\n",
    "    plt.subplot(10, 10, index + 1)\n",
    "    img = Image.open(f'food/{name}.jpg')\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "  print(f'Prediction: {predict([inp])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_example('06592 09283 07104')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66773bfc9a033c4ce678973d2f896b1f255bf0a4029a816f388b108e7ed51c4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
